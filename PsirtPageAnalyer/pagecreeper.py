import requests
import bs4
import html2text
import re
import logging
from requests.exceptions import *
from multiprocessing import Pool
from PsirtPageAnalyer.models import *
from django.db import IntegrityError

class PsirtPageCreeper():
    lenovoSupportHome = 'http://support.lenovo.com'
    severityFlag = 'Severity:'
    cveRep = r'CVE-\d{4}-\d{4}'

    vulCollection = {}


    def clearSpecialChars(self, inputStr):
        if (inputStr is None):
            return ''
        else:
            # print(inputStr.encode('utf-8'))
            return inputStr.replace('\n', '').replace('\\xa0', '').replace(':', '').strip()


    def extractCVEcode(self, contentText):
        return re.findall(self.cveRep, contentText, re.M | re.I)

    def convertSeverityToInteger(self, severity):
        if severity == 'High':
            return 1
        elif severity == 'Medium':
            return 2
        else:
            return 3

    def convertStatusToInteger(self, status):
        if status.replace(' ', '') == 'Notaffected':
            return 0
        elif status == 'Affected':
            return 1
        else:
            return 2

    def parseVulRow(self, tableRow):
        tdElems = tableRow.find_all('td')
        if (len(tdElems) == 0): return None

        strs = list(tdElems[0].strings)
        lenovoCode = self.clearSpecialChars(strs[0])
        description = self.clearSpecialChars(strs[1])

        aElems = tdElems[0].find_all('a')
        link = self.lenovoSupportHome + aElems[0]['href']

        firstDate = self.clearSpecialChars(tdElems[1].string)
        lastDate = self.clearSpecialChars(tdElems[2].string)

        return Vulnerability(lenovoCode=lenovoCode, description=description,
                           link=link, firstPublishedDate=firstDate,
                           lastUpdatedDate=lastDate)


    def parseVulTable(self, vulTable):
        vuls = []
        items = vulTable.find_all('tr')

        # skip the table header line
        for index in range(1, len(items)):
            vul = self.parseVulRow(items[index])
            if vul is not None:
                vuls.append(vul)
        return vuls

    def parseVulDetail(self, vul, entireVulHtml):
        soup = bs4.BeautifulSoup(entireVulHtml, 'html.parser')
        # complete the vulnerability information then save to DB
        pureTextOfContent = html2text.html2text(soup.get_text())  # convert to pure text
        vul.severity = self.extractSeverity(pureTextOfContent)
        vul.cveCodes = repr(self.extractCVEcode(pureTextOfContent))
        try:
            vul.save()
        except (IntegrityError):
            print('duplicate vulnerability code occurred:' + vul.lenovoCode)

        # find all relation business unit and save the business unit information
        buMap = self.dealWithBusinessUnitInformation(vul, soup)

        # deal with product, business unit and vulnerability relationship
        productsContentBlockList = soup.find_all('div', id='NewTileListContent')
        for buKey in buMap.keys():
            self.parseProductsDetail(buKey, buMap[buKey], vul, productsContentBlockList)

    def extractSeverity(self, pureTextOfContent):
        startPos = pureTextOfContent.find(self.severityFlag)
        endPos = pureTextOfContent.find(' ', startPos + len(self.severityFlag) + 1)
        severity = pureTextOfContent[startPos + len(self.severityFlag) + 1: endPos]
        return self.convertSeverityToInteger(severity)

    def dealWithBusinessUnitInformation(self, vul, content):
        buMap = {}
        buAndProdsElem = content.find_all(id='NewTileListComponent')
        if buAndProdsElem is not None and len(buAndProdsElem) > 0:
            for ulElem in buAndProdsElem[0].find_all('ul'):
                for liElem in ulElem.find_all('li'):
                    bu, created = BusinessUnit.objects.get_or_create(name=self.clearSpecialChars(liElem.get_text()))
                    bu.save()
                    buMap[self.clearSpecialChars(liElem['itemindex'])] = bu

        return buMap


    def parseProductsDetail(self, buKey, bu, vul, productsContentBlockList):
        buProductsBlockList = []
        for productsContentBlock in productsContentBlockList:
            buProductsBlockList = productsContentBlock.find_all('div', itemindex=buKey)
            if len(buProductsBlockList) != 0:
                break

        if len(buProductsBlockList) != 0:
            productsTable = buProductsBlockList[0].table
            productRowList = productsTable.find_all('tr')
            if len(productRowList) > 0:
                for index in range(1, len(productRowList)):
                    row = productRowList[index]
                    columns = row.find_all('td')
                    product, created = Product.objects.get_or_create(name=self.clearSpecialChars(columns[0].get_text()))
                    if len(columns) == 2:
                        product.status = self.convertStatusToInteger(columns[1].get_text())
                    elif len(columns) == 4:
                        product.status = self.convertStatusToInteger(columns[1].get_text())
                        product.fixedVersion = self.clearSpecialChars(columns[2].get_text())
                        product.downloadLink = self.clearSpecialChars(columns[3].get_text())
                    else:
                        pass

                    product.save()
                    BUAndProdRelationship(bu = bu, product = product).save()
                    ProdAndVulRelationship(product=product, vul=vul).save()


    def loadPage(self, url):
        print("loading " + url)

        # try three times to avoid the timeout case
        for i in range(3):
            try:
                response = requests.get(url, timeout=30)
                if (response.status_code == 200):
                    soup = bs4.BeautifulSoup(response.text)
                    content = soup.select('div.content-wrapper')[0]
                    return content
            except (ReadTimeout, Timeout, ConnectTimeout):
                print("get a timeout exception on loading: " + url)
                continue

        return ''


    def processDetailPage(self, vul):
        try:
            entireVulContent = self.loadPage(vul.link)
            return entireVulContent.prettify(formatter=None)
        except Exception:
            logging.exception("arg is %s" % vul.lenovoCode)


    def creep(self):
        homeContent = self.loadPage(self.lenovoSupportHome + '/us/en/product_security')
        vuls = self.parseVulTable(homeContent.table)

        # go though all vulnerability element
        pool = Pool(16)
        vulContents = pool.map(self.processDetailPage, vuls)
        pool.close()
        pool.join()

        for index in range(len(vuls)):
             self.parseVulDetail(vuls[index], vulContents[index])
